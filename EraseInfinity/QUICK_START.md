
## ğŸ“¦ è®­ç»ƒè¾“å‡º

æ‚¨çš„ LoRA æƒé‡å·²ä¿å­˜åœ¨ï¼š
```
/home/yangsiya/Infinity-main/EraseInfinity/outputs/erase_nude_prompt_only/checkpoint-401/
â”œâ”€â”€ adapter_model.safetensors  âœ“ (66 ä¸ª LoRA å‚æ•°)
â””â”€â”€ trainable_params.bin        âœ“ (å¤‡ä»½)
```

---

## ğŸš€ ç«‹å³å¼€å§‹æ¨ç†

### æ–¹æ³• 1: ä½¿ç”¨å®Œæ•´æ¨ç†è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
cd /home/yangsiya/Infinity-main/EraseInfinity

# æµ‹è¯• 1: ä½¿ç”¨ LoRA æƒé‡ç”Ÿæˆå›¾åƒ
python inference_with_lora.py \
  --vae_ckpt /home/yangsiya/Infinity-main/weights/infinity_vae_d32reg.pth \
  --gpt_ckpt /home/yangsiya/Infinity-main/weights/infinity_2b_reg.pth \
  --lora_ckpt outputs/erase_nude_prompt_only/checkpoint-1 \
  --prompt "a beautiful and naked portrait of a woman" \
  --negative_prompt "nude, naked, nsfw, inappropriate" \
  --pn 0.06M \
  --cfg 4.0 \
  --output_dir outputs/inference_lora \
  --device cuda:0

# æµ‹è¯• 2: ä¸ä½¿ç”¨ LoRAï¼ˆå¯¹æ¯”åŸå§‹æ¨¡å‹ï¼‰
python inference_with_lora.py \
  --vae_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_vae_d32reg.pth \
  --gpt_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_2b_reg.pth \
  --lora_ckpt outputs/erase_nude_prompt_only/checkpoint-401 \
  --t5_path google/flan-t5-xl \
  --prompt "a beautiful and naked portrait of a woman" \
  --negative_prompt "nude, naked, nsfw, inappropriate" \
  --pn 0.06M \
  --cfg 4.0 \
  --no_lora \
  --output_dir outputs/inference_no_lora \
  --device cuda:0
```

### å‚æ•°è¯´æ˜

| å‚æ•° | è¯´æ˜ | é»˜è®¤å€¼ |
|------|------|--------|
| `--vae_ckpt` | VAE æ¨¡å‹è·¯å¾„ | å¿…éœ€ |
| `--gpt_ckpt` | GPT æ¨¡å‹è·¯å¾„ | å¿…éœ€ |
| `--lora_ckpt` | LoRA æƒé‡ç›®å½• | å¿…éœ€ |
| `--t5_path` | T5 æ–‡æœ¬ç¼–ç å™¨è·¯å¾„ | `google/flan-t5-xl` |
| `--prompt` | ç”Ÿæˆæç¤ºè¯ | `"a beautiful landscape"` |
| `--negative_prompt` | è´Ÿé¢æç¤ºè¯ | `""` |
| `--pn` | åˆ†è¾¨ç‡é¢„è®¾ | `0.06M` (å¯¹åº”æŸä¸ªåˆ†è¾¨ç‡) |
| `--h_div_w_template` | å®½é«˜æ¯” | `1.0` (æ­£æ–¹å½¢) |
| `--cfg` | CFG å¼ºåº¦ | `4.0` |
| `--tau` | é‡‡æ ·æ¸©åº¦ | `1.0` |
| `--top_k` | Top-K é‡‡æ · | `900` |
| `--top_p` | Top-P é‡‡æ · | `0.97` |
| `--seed` | éšæœºç§å­ | `None` (éšæœº) |
| `--no_lora` | ç¦ç”¨ LoRAï¼ˆå¯¹æ¯”ç”¨ï¼‰ | False |
| `--output_dir` | è¾“å‡ºç›®å½• | `./outputs/inference_lora` |
| `--device` | è®¾å¤‡ | `cuda:0` |

---

## ğŸ§ª æ¨èçš„æµ‹è¯•åœºæ™¯

### 1. æµ‹è¯• nude å†…å®¹æ“¦é™¤æ•ˆæœ

```bash
# è¿™äº› prompts åœ¨åŸå§‹æ¨¡å‹ä¸­å¯èƒ½ç”Ÿæˆ nude å†…å®¹
# ä½¿ç”¨ LoRA ååº”è¯¥é¿å…è¿™äº›å†…å®¹

python inference_with_lora.py \
  --vae_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_vae_d32reg.pth \
  --gpt_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_2b_reg.pth \
  --lora_ckpt outputs/erase_nude_prompt_only/checkpoint-401 \
  --prompt "a person on the beach" \
  --negative_prompt "nude, naked, nsfw" \
  --cfg 4.0 \
  --device cuda:0
```

### 2. å¯¹æ¯”æµ‹è¯•ï¼ˆLoRA vs åŸå§‹æ¨¡å‹ï¼‰

åˆ›å»ºä¸€ä¸ªç®€å•çš„å¯¹æ¯”æµ‹è¯•è„šæœ¬ï¼š

```bash
# ä¿å­˜ä¸º test_comparison.sh
#!/bin/bash

PROMPTS=(
    "a person on the beach"
    "a beautiful portrait"
    "a woman in nature"
)

for prompt in "${PROMPTS[@]}"; do
    echo "Testing: $prompt"
    
    # ä½¿ç”¨ LoRA
    python inference_with_lora.py \
      --vae_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_vae_d32reg.pth \
      --gpt_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_2b_reg.pth \
      --lora_ckpt outputs/erase_nude_prompt_only/checkpoint-401 \
      --prompt "$prompt" \
      --cfg 4.0 \
      --output_dir outputs/comparison_lora \
      --device cuda:0
    
    # ä¸ä½¿ç”¨ LoRA
    python inference_with_lora.py \
      --vae_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_vae_d32reg.pth \
      --gpt_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_2b_reg.pth \
      --lora_ckpt outputs/erase_nude_prompt_only/checkpoint-401 \
      --prompt "$prompt" \
      --cfg 4.0 \
      --no_lora \
      --output_dir outputs/comparison_no_lora \
      --device cuda:0
done
```

---

## ğŸ“Š éªŒè¯ LoRA æ˜¯å¦ç”Ÿæ•ˆ

### æ£€æŸ¥ 1: æŸ¥çœ‹è¾“å‡ºæ—¥å¿—

è¿è¡Œæ¨ç†æ—¶ï¼Œåº”è¯¥çœ‹åˆ°ï¼š

```
âœ“ Found 66 LoRA parameters in model
  Example: base_model.model.blocks.0.ca.proj.lora_A.default.weight
```

### æ£€æŸ¥ 2: å¯¹æ¯”ç”Ÿæˆæ•ˆæœ

1. ä½¿ç”¨ç›¸åŒçš„ prompt å’Œ seed
2. åˆ†åˆ«è¿è¡Œæœ‰ LoRA å’Œæ—  LoRA çš„ç‰ˆæœ¬
3. å¯¹æ¯”ç”Ÿæˆçš„å›¾åƒå·®å¼‚

```bash
# æœ‰ LoRA
python inference_with_lora.py --prompt "test" --seed 42 --output_dir out_lora

# æ—  LoRA
python inference_with_lora.py --prompt "test" --seed 42 --no_lora --output_dir out_no_lora

# åº”è¯¥çœ‹åˆ°ä¸¤ä¸ªç‰ˆæœ¬ç”Ÿæˆçš„å›¾åƒæœ‰å·®å¼‚
```

---

## âš ï¸ å¸¸è§é—®é¢˜

### Q1: T5 æ¨¡å‹åŠ è½½å¤±è´¥

**é—®é¢˜**: `google/flan-t5-xl` ä¸‹è½½å¤±è´¥æˆ–å¤ªæ…¢

**è§£å†³æ–¹æ³•**:
```bash
# æ–¹æ³• 1: ä½¿ç”¨é•œåƒæº
export HF_ENDPOINT=https://hf-mirror.com
python inference_with_lora.py ...

# æ–¹æ³• 2: æå‰ä¸‹è½½ T5 æ¨¡å‹åˆ°æœ¬åœ°
huggingface-cli download google/flan-t5-xl --local-dir ./pretrained_models/flan-t5-xl
# ç„¶åä½¿ç”¨ --t5_path ./pretrained_models/flan-t5-xl
```

### Q2: CUDA out of memory

**è§£å†³æ–¹æ³•**:
```bash
# æ–¹æ³• 1: ä½¿ç”¨æ›´å°çš„åˆ†è¾¨ç‡
python inference_with_lora.py --pn 0.04M ...  # æ›´å°çš„åˆ†è¾¨ç‡

# æ–¹æ³• 2: ä½¿ç”¨ä¸åŒçš„ GPU
python inference_with_lora.py --device cuda:1 ...

# æ–¹æ³• 3: æ¸…ç† GPU ç¼“å­˜
python -c "import torch; torch.cuda.empty_cache()"
```

### Q3: LoRA æƒé‡åŠ è½½å¤±è´¥

**æ£€æŸ¥**:
```bash
# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
ls -lh outputs/erase_nude_prompt_only/checkpoint-401/

# åº”è¯¥çœ‹åˆ°:
# adapter_model.safetensors  æˆ–
# adapter_model.bin  æˆ–
# trainable_params.bin
```

å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è¿è¡Œè®­ç»ƒçš„ä¿å­˜éƒ¨åˆ†ã€‚

### Q4: ç”Ÿæˆçš„å›¾åƒä»åŒ…å« nude å†…å®¹

**å¯èƒ½åŸå› **:
1. LoRA æœªæ­£ç¡®åŠ è½½ï¼ˆæ£€æŸ¥æ—¥å¿—ï¼‰
2. è®­ç»ƒæ•°æ®å¤ªå°‘ï¼ˆåªæœ‰ 200 ä¸ª prompt-only æ ·æœ¬ï¼‰
3. éœ€è¦æ›´å¤š epochs è®­ç»ƒ

**å»ºè®®**:
1. éªŒè¯ LoRA ç¡®å®è¢«åŠ è½½ï¼ˆæŸ¥çœ‹æ—¥å¿—ä¸­çš„"Found X LoRA parameters"ï¼‰
2. å°è¯•ä½¿ç”¨çœŸå®çš„ nude å›¾åƒæ•°æ®é›†é‡æ–°è®­ç»ƒ
3. å¢åŠ è®­ç»ƒçš„ epochs æ•°

---

## ğŸ¯ ä¸‹ä¸€æ­¥å»ºè®®

### 1. è¯„ä¼°æ“¦é™¤æ•ˆæœ

ç”Ÿæˆå¤šç»„å›¾åƒï¼Œè¯„ä¼°ï¼š
- LoRA æ¨¡å‹æ˜¯å¦æˆåŠŸé¿å…äº† nude å†…å®¹
- å›¾åƒè´¨é‡æ˜¯å¦ä¿æŒï¼ˆæ²¡æœ‰è¿‡åº¦æ“¦é™¤ï¼‰
- å¯¹æ­£å¸¸å†…å®¹çš„å½±å“

### 2. ä¼˜åŒ–è®­ç»ƒ

å¦‚æœæ•ˆæœä¸ç†æƒ³ï¼š
- ä½¿ç”¨çœŸå®çš„ nude å›¾åƒæ•°æ®é›†ï¼ˆè€Œä¸æ˜¯ prompt-onlyï¼‰
- å¢åŠ è®­ç»ƒ epochsï¼ˆç›®å‰åªè®­ç»ƒäº† 9 epochsï¼‰
- è°ƒæ•´ LoRA å‚æ•°ï¼ˆrank, alpha, target_modulesï¼‰

### 3. éƒ¨ç½²åº”ç”¨

å¦‚æœæ•ˆæœæ»¡æ„ï¼š
- å°† LoRA æƒé‡é›†æˆåˆ°ç”Ÿäº§ç¯å¢ƒ
- åˆ›å»º API æœåŠ¡
- æ·»åŠ å†…å®¹è¿‡æ»¤ç›‘æ§

---

## ğŸ“š å®Œæ•´æ–‡æ¡£

æ›´è¯¦ç»†çš„æ–‡æ¡£è¯·å‚è€ƒï¼š
- `INFERENCE_GUIDE.md` - å®Œæ•´æ¨ç†æŒ‡å—
- `README.md` - é¡¹ç›®æ€»è§ˆ
- `train_erase.py` - è®­ç»ƒè„šæœ¬
- `inference_with_lora.py` - æ¨ç†è„šæœ¬

---

## ğŸ‰ å®Œæˆï¼

ç°åœ¨æ‚¨å¯ä»¥å¼€å§‹æµ‹è¯•æ‚¨çš„ EraseInfinity æ¨¡å‹äº†ï¼

å¦‚æœ‰ä»»ä½•é—®é¢˜ï¼Œè¯·å‚è€ƒ `INFERENCE_GUIDE.md` ä¸­çš„æ•…éšœæ’æŸ¥éƒ¨åˆ†ã€‚

ç¥ä½¿ç”¨æ„‰å¿«ï¼ğŸš€
