# EraseInfinity æ¨ç†æŒ‡å—

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜å¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„ LoRA æƒé‡è¿›è¡Œæ¨ç†ã€‚

---

## ğŸ“Š è®­ç»ƒç»“æœæ€»ç»“

æ ¹æ®æ‚¨çš„è®­ç»ƒè¾“å‡ºï¼š

### è®­ç»ƒé…ç½®
- **è®­ç»ƒè½®æ•°**: 9 epochs
- **æ•°æ®é›†å¤§å°**: 200 samples (Prompt-Only Dataset)
- **Batch size**: 4
- **æ¯è½®æ­¥æ•°**: 50 steps
- **æ€»è®­ç»ƒæ­¥æ•°**: 450 steps

### Loss æ”¶æ•›æƒ…å†µ
```
Epoch 0: Loss 0.2306
Epoch 1: Loss 0.0152  (â†“ 93.4%)
Epoch 2: Loss 0.0086  (â†“ 43.4%)
Epoch 3: Loss 0.0045  (â†“ 47.7%)
Epoch 4: Loss 0.0031  (â†“ 31.1%)
Epoch 5: Loss 0.0085  (â†‘ 174.2%) - å¯èƒ½æ˜¯å­¦ä¹ ç‡è°ƒæ•´æˆ–æ•°æ®éšæœºæ€§
Epoch 6: Loss 0.0041  (â†“ 51.8%)
Epoch 7: Loss 0.0028  (â†“ 31.7%)
Epoch 8: Loss 0.0042  (â†‘ 50.0%)
```

âœ… **æ€»ä½“æ¥è¯´ï¼ŒLoss ä» 0.2306 é™åˆ°äº† 0.0042ï¼Œä¸‹é™äº† 98.2%ï¼Œæ˜¾ç¤ºå‡ºè‰¯å¥½çš„å­¦ä¹ æ•ˆæœï¼**

### ä¿å­˜çš„æ¨¡å‹æƒé‡
è®­ç»ƒå®Œæˆåï¼ŒLoRA æƒé‡å·²ä¿å­˜åœ¨ï¼š
```
EraseInfinity/outputs/erase_nude_prompt_only/
â”œâ”€â”€ checkpoint-401/
â”‚   â”œâ”€â”€ adapter_model.safetensors  (66 ä¸ª LoRA å‚æ•°)
â”‚   â””â”€â”€ trainable_params.bin       (fallback ä¿å­˜çš„æƒé‡)
â””â”€â”€ loss_curves1.png                (è®­ç»ƒ loss æ›²çº¿å›¾)
```

---

## ğŸš€ å¦‚ä½•ä½¿ç”¨è®­ç»ƒå¥½çš„ LoRA æƒé‡

### æ–¹æ³• 1: ä½¿ç”¨æä¾›çš„æ¨ç†è„šæœ¬ï¼ˆæ¨èï¼‰

æˆ‘å·²ç»ä¸ºæ‚¨åˆ›å»ºäº† `inference_erase.py` è„šæœ¬ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨ï¼š

```bash
cd /home/yangsiya/Infinity-main/EraseInfinity

python inference_erase.py \
  --vae_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_vae_d32reg.pth \
  --gpt_ckpt /home/yangsiya/Infinity-main/pretrained_models/infinity_2b_reg.pth \
  --lora_ckpt outputs/erase_nude_prompt_only/checkpoint-401 \
  --prompt "a beautiful landscape" \
  --negative_prompt "nude, naked, nsfw" \
  --resolution 1024 \
  --num_images 4 \
  --cfg_scale 4.0 \
  --output_dir outputs/inference \
  --device cuda:0
```

**å‚æ•°è¯´æ˜ï¼š**
- `--vae_ckpt`: VAE æ¨¡å‹æƒé‡è·¯å¾„
- `--gpt_ckpt`: GPT æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆåŸå§‹é¢„è®­ç»ƒæƒé‡ï¼‰
- `--lora_ckpt`: è®­ç»ƒå¥½çš„ LoRA æƒé‡ç›®å½•
- `--prompt`: ç”Ÿæˆå›¾åƒçš„æ–‡æœ¬æç¤º
- `--negative_prompt`: è´Ÿé¢æç¤ºï¼ˆè¦é¿å…çš„å†…å®¹ï¼‰
- `--resolution`: å›¾åƒåˆ†è¾¨ç‡
- `--num_images`: ç”Ÿæˆå›¾åƒæ•°é‡
- `--cfg_scale`: Classifier-free guidance å¼ºåº¦
- `--output_dir`: è¾“å‡ºç›®å½•
- `--device`: ä½¿ç”¨çš„è®¾å¤‡ï¼ˆcuda:0, cuda:1, cpu ç­‰ï¼‰

---

### æ–¹æ³• 2: åœ¨ Infinity åŸç”Ÿæ¨ç†ä»£ç ä¸­åŠ è½½ LoRA

å¦‚æœæ‚¨æƒ³åœ¨ Infinity çš„åŸç”Ÿæ¨ç†è„šæœ¬ä¸­ä½¿ç”¨ LoRA æƒé‡ï¼Œéœ€è¦ä¿®æ”¹æ¨ç†ä»£ç ï¼š

#### æ­¥éª¤ 1: åœ¨æ„å»ºæ¨¡å‹ååŠ è½½ LoRA

```python
# åœ¨ Infinity çš„æ¨ç†è„šæœ¬ä¸­ï¼Œæ‰¾åˆ°æ¨¡å‹æ„å»ºçš„ä»£ç 
# é€šå¸¸åœ¨ inference/sample.py æˆ–ç±»ä¼¼æ–‡ä»¶ä¸­

# åŸå§‹ä»£ç ï¼š
vae, gpt_model, _ = build_vae_gpt(args, vae_ckpt, skip_gpt=False, device='cpu')
gpt_model = gpt_model.to(device)

# åœ¨åŠ è½½åŸå§‹æƒé‡åï¼Œæ·»åŠ  LoRA åŠ è½½ä»£ç ï¼š
from peft import PeftModel

# åŠ è½½ LoRA æƒé‡
lora_ckpt_path = "EraseInfinity/outputs/erase_nude_prompt_only/checkpoint-401"
print(f"Loading LoRA weights from {lora_ckpt_path}")

try:
    # æ–¹æ³• 1: ä½¿ç”¨ PeftModel.from_pretrainedï¼ˆæ¨èï¼‰
    gpt_model = PeftModel.from_pretrained(gpt_model, lora_ckpt_path)
    print("âœ“ LoRA weights loaded successfully")
except Exception as e:
    print(f"Warning: Failed to load LoRA using PeftModel: {e}")
    
    # æ–¹æ³• 2: æ‰‹åŠ¨åŠ è½½æƒé‡ï¼ˆfallbackï¼‰
    from safetensors.torch import load_file
    lora_state_dict = load_file(f"{lora_ckpt_path}/adapter_model.safetensors")
    gpt_model.load_state_dict(lora_state_dict, strict=False)
    print("âœ“ LoRA weights loaded manually")

# è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
gpt_model.eval()
```

#### æ­¥éª¤ 2: æ­£å¸¸è¿›è¡Œæ¨ç†

åŠ è½½ LoRA åï¼Œæ¨¡å‹çš„ä½¿ç”¨æ–¹å¼ä¸åŸå§‹æ¨¡å‹å®Œå…¨ç›¸åŒï¼Œä¸éœ€è¦ä¿®æ”¹æ¨ç†é€»è¾‘ã€‚

---

## ğŸ” éªŒè¯ LoRA æ˜¯å¦ç”Ÿæ•ˆ

### æ–¹æ³• 1: æ£€æŸ¥æ¨¡å‹å‚æ•°

```python
# åŠ è½½ LoRA åï¼Œæ£€æŸ¥æ¨¡å‹æ˜¯å¦æœ‰ LoRA å‚æ•°
lora_params = []
for name, param in gpt_model.named_parameters():
    if 'lora' in name.lower():
        lora_params.append(name)

print(f"Found {len(lora_params)} LoRA parameters")
for name in lora_params[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
    print(f"  - {name}")
```

é¢„æœŸè¾“å‡ºï¼š
```
Found 66 LoRA parameters
  - base_model.model.blocks.0.ca.proj.lora_A.default.weight
  - base_model.model.blocks.0.ca.proj.lora_B.default.weight
  - base_model.model.blocks.1.ca.proj.lora_A.default.weight
  - base_model.model.blocks.1.ca.proj.lora_B.default.weight
  - base_model.model.blocks.2.ca.proj.lora_A.default.weight
```

### æ–¹æ³• 2: å¯¹æ¯”ç”Ÿæˆæ•ˆæœ

1. **åŠ è½½åŸå§‹æ¨¡å‹**ï¼šç”Ÿæˆå›¾åƒï¼Œçœ‹æ˜¯å¦åŒ…å« nude å†…å®¹
2. **åŠ è½½ LoRA æ¨¡å‹**ï¼šç”Ÿæˆç›¸åŒ prompt çš„å›¾åƒï¼Œçœ‹æ˜¯å¦æˆåŠŸæ“¦é™¤ nude å†…å®¹

---

## ğŸ“ æ¨ç†ä»£ç ç¤ºä¾‹

### å®Œæ•´çš„ Python æ¨ç†ä»£ç 

```python
import torch
from peft import PeftModel
from infinity.utils.load import build_vae_gpt

# è®¾å¤‡é…ç½®
device = torch.device("cuda:0")

# 1. åŠ è½½ VAE å’Œ GPT
vae_ckpt = torch.load("pretrained_models/infinity_vae_d32reg.pth", map_location='cpu')
gpt_ckpt = torch.load("pretrained_models/infinity_2b_reg.pth", map_location='cpu')

# æ„å»ºæ¨¡å‹ï¼ˆéœ€è¦æä¾› argsï¼Œå‚è€ƒ inference_erase.pyï¼‰
vae, gpt_model, _ = build_vae_gpt(args, vae_ckpt, skip_gpt=False, device='cpu')

# åŠ è½½ GPT æƒé‡
if 'trainer' in gpt_ckpt:
    gpt_state_dict = gpt_ckpt['trainer'].get('gpt_wo_ddp', gpt_ckpt)
else:
    gpt_state_dict = gpt_ckpt
gpt_model.load_state_dict(gpt_state_dict, strict=False)

# 2. åŠ è½½ LoRA æƒé‡
lora_path = "EraseInfinity/outputs/erase_nude_prompt_only/checkpoint-401"
gpt_model = PeftModel.from_pretrained(gpt_model, lora_path)

# 3. ç§»åŠ¨åˆ°è®¾å¤‡å¹¶è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
vae = vae.to(device).eval()
gpt_model = gpt_model.to(device).eval()

# 4. å‡†å¤‡æ–‡æœ¬ç‰¹å¾
# ï¼ˆéœ€è¦æ ¹æ® Infinity çš„å®é™…æ–‡æœ¬ç¼–ç æ–¹å¼ï¼‰
prompt = "a beautiful portrait"
# text_features = encode_text(prompt)  # å…·ä½“å®ç°å‚è€ƒ Infinity ä»£ç 

# 5. ç”Ÿæˆå›¾åƒ
with torch.no_grad():
    # è°ƒç”¨ Infinity çš„ç”Ÿæˆå‡½æ•°
    # generated_images = gpt_model.generate(...)
    pass

# 6. è§£ç å¹¶ä¿å­˜
# images = vae.decode(generated_images)
# save_images(images, "outputs/")
```

---

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

### 1. æ¨ç†æ¥å£ä¾èµ– Infinity çš„å®ç°

**å½“å‰çŠ¶æ€**: `inference_erase.py` æä¾›äº†æ¨¡å‹åŠ è½½çš„æ¡†æ¶ï¼Œä½†å®é™…çš„å›¾åƒç”Ÿæˆéƒ¨åˆ†éœ€è¦æ ¹æ® Infinity çš„å…·ä½“ API æ¥å®ç°ã€‚

**æ‚¨éœ€è¦åšçš„**:
1. æŸ¥çœ‹ Infinity é¡¹ç›®ä¸­çš„æ¨ç†ä»£ç ï¼ˆé€šå¸¸åœ¨ `infinity/inference/` æˆ–ç±»ä¼¼ç›®å½•ï¼‰
2. æ‰¾åˆ°å›¾åƒç”Ÿæˆçš„å‡½æ•°ï¼ˆå¦‚ `generate()`, `sample()`, `autoregressive_infer()` ç­‰ï¼‰
3. å°†è¯¥å‡½æ•°é›†æˆåˆ° `inference_erase.py` ä¸­

### 2. æ–‡æœ¬ç¼–ç æ–¹å¼

è®­ç»ƒæ—¶æˆ‘ä»¬ä½¿ç”¨äº†ç®€åŒ–çš„æ–‡æœ¬ç¼–ç ï¼ˆåŸºäº `cfg_uncond` çš„æ‰°åŠ¨ï¼‰ï¼Œè¿™å¯èƒ½ä¸ Infinity åŸç”Ÿçš„æ–‡æœ¬ç¼–ç ä¸å®Œå…¨ä¸€è‡´ã€‚

**å»ºè®®**:
- å¦‚æœ Infinity æœ‰ T5 æ–‡æœ¬ç¼–ç å™¨ï¼Œå»ºè®®ä½¿ç”¨å®ƒæ¥è·å¾—æ›´å¥½çš„æ•ˆæœ
- å¦‚æœè¦ä¿æŒä¸€è‡´æ€§ï¼Œæ¨ç†æ—¶ä¹Ÿåº”è¯¥ä½¿ç”¨ç›¸åŒçš„æ–‡æœ¬ç¼–ç æ–¹å¼ï¼ˆ`create_text_features_from_prompts`ï¼‰

### 3. LoRA æƒé‡å…¼å®¹æ€§

è®­ç»ƒæ—¶æˆ‘ä»¬åªå¯¹ Cross-Attention çš„ `proj` å±‚æ·»åŠ äº† LoRAï¼ˆ66ä¸ªå‚æ•°ï¼‰ã€‚æ¨ç†æ—¶ï¼š
- âœ… å¯ä»¥ç›´æ¥ç”¨ `PeftModel.from_pretrained()` åŠ è½½
- âœ… åŸå§‹æ¨¡å‹æƒé‡ä¸ä¼šè¢«ä¿®æ”¹ï¼Œåªæ˜¯æ·»åŠ äº† LoRA é€‚é…å™¨
- âœ… å¦‚æœéœ€è¦ï¼Œå¯ä»¥éšæ—¶ç¦ç”¨ LoRAï¼š`gpt_model.disable_adapter_layers()`

---

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: æ‰¾ä¸åˆ° Infinity çš„æ¨ç†ä»£ç 

**è§£å†³æ–¹æ³•**:
```bash
# åœ¨ Infinity é¡¹ç›®ä¸­æœç´¢æ¨ç†ç›¸å…³ä»£ç 
cd /home/yangsiya/Infinity-main
find . -name "*.py" -type f | xargs grep -l "def generate\|def sample\|def infer"

# æˆ–è€…æŸ¥çœ‹æ˜¯å¦æœ‰ demo æˆ– example è„šæœ¬
ls -la demos/ examples/ scripts/
```

### é—®é¢˜ 2: LoRA åŠ è½½å¤±è´¥

**å¯èƒ½åŸå› **:
- PEFT åº“ç‰ˆæœ¬ä¸å…¼å®¹
- `adapter_config.json` æ ¼å¼é”™è¯¯ï¼ˆå·²åœ¨è®­ç»ƒè„šæœ¬ä¸­ä¿®å¤ï¼‰

**è§£å†³æ–¹æ³•**:
```python
# å°è¯•æ‰‹åŠ¨åŠ è½½æƒé‡
from safetensors.torch import load_file

lora_weights = load_file("outputs/checkpoint-401/adapter_model.safetensors")
print(f"Loaded {len(lora_weights)} parameters:")
for k in list(lora_weights.keys())[:5]:
    print(f"  {k}: {lora_weights[k].shape}")

# æ‰‹åŠ¨åŠ è½½åˆ°æ¨¡å‹
gpt_model.load_state_dict(lora_weights, strict=False)
```

### é—®é¢˜ 3: ç”Ÿæˆçš„å›¾åƒä»åŒ…å« nude å†…å®¹

**å¯èƒ½åŸå› **:
- LoRA æƒé‡æœªæ­£ç¡®åŠ è½½
- è®­ç»ƒçš„ epoch æ•°ä¸å¤Ÿ
- è®­ç»ƒæ•°æ®é›†å¤ªå°ï¼ˆåªæœ‰ 200 ä¸ª prompt-only æ ·æœ¬ï¼‰

**è§£å†³æ–¹æ³•**:
1. éªŒè¯ LoRA æ˜¯å¦çœŸçš„åŠ è½½äº†ï¼ˆå‚è€ƒ"éªŒè¯ LoRA æ˜¯å¦ç”Ÿæ•ˆ"ï¼‰
2. å°è¯•ä½¿ç”¨æ›´å¤š epochs é‡æ–°è®­ç»ƒ
3. å¦‚æœéœ€è¦æ›´å¥½çš„æ•ˆæœï¼Œä½¿ç”¨çœŸå®çš„ nude å›¾åƒæ•°æ®é›†è¿›è¡Œè®­ç»ƒ

---

## ğŸ“š ä¸‹ä¸€æ­¥å»ºè®®

### 1. æ‰¾åˆ° Infinity çš„æ¨ç†ä»£ç 

```bash
# æŸ¥çœ‹ Infinity é¡¹ç›®ç»“æ„
cd /home/yangsiya/Infinity-main
ls -la
ls -la infinity/

# æŸ¥æ‰¾æ¨ç†ç›¸å…³æ–‡ä»¶
find . -name "*infer*" -o -name "*sample*" -o -name "*generate*"
```

### 2. é›†æˆæ¨ç†ä»£ç åˆ° inference_erase.py

å°† Infinity çš„æ¨ç†é€»è¾‘æ·»åŠ åˆ° `generate_images()` å‡½æ•°ä¸­ã€‚

### 3. æµ‹è¯•ä¸åŒçš„ prompts

```bash
# æµ‹è¯•åŸæœ¬ä¼šç”Ÿæˆ nude å†…å®¹çš„ prompt
python inference_erase.py \
  --prompt "a person on the beach" \
  --negative_prompt "nude, naked, nsfw" \
  ...

# å¯¹æ¯”ï¼šä½¿ç”¨åŸå§‹æ¨¡å‹ç”Ÿæˆï¼ˆä¸åŠ è½½ LoRAï¼‰
# åº”è¯¥çœ‹åˆ° LoRA æ¨¡å‹æˆåŠŸé¿å…äº† nude å†…å®¹
```

---

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

å¦‚æœæ‚¨åœ¨æ¨ç†è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼š

1. **æŸ¥çœ‹è®­ç»ƒæ—¥å¿—**: `outputs/erase_nude_prompt_only/loss_log1.txt`
2. **æ£€æŸ¥ LoRA æƒé‡**: ç¡®è®¤ `adapter_model.safetensors` æ–‡ä»¶å­˜åœ¨ä¸”å¤§å°åˆç†
3. **é˜…è¯» Infinity æ–‡æ¡£**: æŸ¥çœ‹ Infinity é¡¹ç›®çš„ README å’Œæ–‡æ¡£
4. **è°ƒè¯•æ¨¡å¼**: åœ¨ Python ä¸­é€æ­¥è¿è¡Œä»£ç ï¼Œæ£€æŸ¥æ¯ä¸€æ­¥çš„è¾“å‡º

---

## ğŸ‰ æ€»ç»“

æ‚¨å·²ç»æˆåŠŸè®­ç»ƒäº†ä¸€ä¸ª EraseInfinity æ¨¡å‹ï¼

- âœ… è®­ç»ƒå®Œæˆï¼ŒLoss ä» 0.23 é™åˆ° 0.004
- âœ… LoRA æƒé‡å·²ä¿å­˜ï¼ˆ66 ä¸ªå‚æ•°ï¼‰
- âœ… æ¨ç†è„šæœ¬å·²å‡†å¤‡å¥½
- â³ ä¸‹ä¸€æ­¥ï¼šé›†æˆ Infinity çš„æ¨ç† API å¹¶æµ‹è¯•æ•ˆæœ

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸš€

